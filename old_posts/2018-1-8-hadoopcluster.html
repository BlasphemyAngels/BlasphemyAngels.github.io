<h3 id="搭建hadoop275集群">搭建hadoop2.7.5集群</h3>

<blockquote>组内最近要搭建一个`spark`平台，先让我们探探路，于是我就去阿里云和腾讯云各租了一台服务器用来搭建一个`hadoop`集群(-_-)。</blockquote>

<!--more-->

<p>talk is check, action!</p>

<h4 id="环境准备">环境准备</h4>

<h5 id="系统信息">系统信息</h5>

<p>两台服务器的系统都是<code class="language-plaintext highlighter-rouge">cent os 7.3</code>，其他版本也是大同小异。</p>

<h5 id="创建用户">创建用户</h5>

<p>在每台结点上创建一个名为<code class="language-plaintext highlighter-rouge">hadoop</code>的用户并修改密码：</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>useradd hadoop
passwd hadoop
</code></pre></div></div>

<p>我们的<code class="language-plaintext highlighter-rouge">hadoop</code>程序都是部署在每台结点的<code class="language-plaintext highlighter-rouge">hadoop</code>用户上的，所以本文以后的操作如无特别说明，都是在<code class="language-plaintext highlighter-rouge">hadoop</code>用户上进行。</p>

<h5 id="配置jdk">配置jdk</h5>

<p>先安装<code class="language-plaintext highlighter-rouge">jdk</code>：</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>yum <span class="nb">install </span>java-1.8.0-openjdk.x86_64
</code></pre></div></div>

<p>再配置环境变量：</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/lib/jvm/java-1.8.0-openjdk
</code></pre></div></div>

<h5 id="配置hosts文件">配置hosts文件</h5>

<p>我这两个服务器的外网<code class="language-plaintext highlighter-rouge">ip</code>和内网<code class="language-plaintext highlighter-rouge">ip</code>为：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"> </th>
      <th style="text-align: center">公网ip</th>
      <th style="text-align: center">内网ip</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">服务器1</td>
      <td style="text-align: center">node1_ip_1</td>
      <td style="text-align: center">node1_ip_2</td>
    </tr>
    <tr>
      <td style="text-align: center">服务器2</td>
      <td style="text-align: center">node2_ip_1</td>
      <td style="text-align: center">node2_ip_2</td>
    </tr>
  </tbody>
</table>

<p>在<code class="language-plaintext highlighter-rouge">node1</code>的<code class="language-plaintext highlighter-rouge">/etc/hosts</code>文件后面添加下入面内容：</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>node1_ip_2  node1    node1
node2_ip_1  node2    node2
</code></pre></div></div>
<p>在<code class="language-plaintext highlighter-rouge">node2</code>的<code class="language-plaintext highlighter-rouge">/etc/hosts</code>文件后面加入下面内容：</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>node1_ip_1  node1   node1
node2_ip_2  node2   node2
</code></pre></div></div>

<p>可以发现在给<code class="language-plaintext highlighter-rouge">A</code>结点配置<code class="language-plaintext highlighter-rouge">hosts</code>文件时，除了<code class="language-plaintext highlighter-rouge">A</code>结点外，在<code class="language-plaintext highlighter-rouge">hosts</code>文件内配置的都是外网<code class="language-plaintext highlighter-rouge">ip</code>，而<code class="language-plaintext highlighter-rouge">A</code>结点本身的配置只能是内网<code class="language-plaintext highlighter-rouge">ip</code>，其他结点类似。注意这一点很重要，不然会导致无法启动<code class="language-plaintext highlighter-rouge">namenode</code>。（很重要，血的教训）</p>

<h5 id="配置免密码登录">配置免密码登录</h5>

<p>配置所有结点间的<code class="language-plaintext highlighter-rouge">ssh</code>免密码登录。原理就是如果要配置结点<code class="language-plaintext highlighter-rouge">A</code>免密码登录<code class="language-plaintext highlighter-rouge">B</code>，那么只需要将<code class="language-plaintext highlighter-rouge">A</code>结点下<code class="language-plaintext highlighter-rouge">.ssh</code>目录下的公钥（一般为<code class="language-plaintext highlighter-rouge">id_rsa.pub</code>文件的你内容）复制到结点<code class="language-plaintext highlighter-rouge">B</code>的<code class="language-plaintext highlighter-rouge">.ssh/authorized_keys</code>文件中即可。</p>

<p>这个操作使用<code class="language-plaintext highlighter-rouge">scp-copy-id</code>命令完成即可。</p>

<p>比如在这里的<code class="language-plaintext highlighter-rouge">node1</code>需要进行如下配置</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh-keygen <span class="c"># 产生秘钥</span>
ssh-copy-id localhost
ssh-copy-id <span class="nt">-i</span> ~/.ssh/id_rsa.pub hadoop@node2
</code></pre></div></div>
<p>结点<code class="language-plaintext highlighter-rouge">node2</code>是一样的。</p>

<h5 id="打开阿里云服务器的端口">打开阿里云服务器的端口</h5>

<p>如果是使用的阿里云或者腾讯云，这些服务器的端口默认是关闭的（包括22号端口），要打开的话要登录相应的官网，找到安全组规则，点击快速添加规则，填写下图的内容便打开了所有的端口。</p>

<p><img src="https://github.com/BlasphemyAngels/MarkDownPhotos/blob/master/guize.png?raw=true" alt="guize" /></p>

<h4 id="hadoop配置">hadoop配置</h4>

<h5 id="下载hadoop">下载hadoop</h5>

<p>在所有结点运行：</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code> wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-2.8.1/hadoop-2.8.1.tar.gz <span class="nt">-P</span> /tmp
 <span class="nb">tar</span> <span class="nt">-xf</span> /tmp/hadoop-2.8.1.tar.gz <span class="nt">-C</span> /usr/local/hadoop <span class="nt">--strip-components</span> 1
</code></pre></div></div>

<h5 id="配置hadoop运行环境">配置hadoop运行环境</h5>

<p>在所有结点的<code class="language-plaintext highlighter-rouge">~/.bash_profile</code>中加入下面内容：</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">HADOOP_HOME</span><span class="o">=</span>/usr/local/hadoop
<span class="nb">export </span><span class="nv">HADOOP_COMMON_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_HDFS_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_MAPRED_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_YARN_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_OPTS</span><span class="o">=</span><span class="s2">"-Djava.library.path=</span><span class="nv">$HADOOP_HOME</span><span class="s2">/lib/native"</span>
<span class="nb">export </span><span class="nv">HADOOP_COMMON_LIB_NATIVE_DIR</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>/lib/native
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HADOOP_HOME</span>/sbin:<span class="nv">$HADOOP_HOME</span>/bin
</code></pre></div></div>

<p>执行<code class="language-plaintext highlighter-rouge">source ~/.bash_profile</code>即可。</p>

<h5 id="修改配置文件">修改配置文件</h5>

<p>对所有结点的<code class="language-plaintext highlighter-rouge">$HADOOP_HOME/etc/hadoop/</code>中的配置文件做如下配置：</p>

<p>在<code class="language-plaintext highlighter-rouge">hadoop-env.sh</code>中加入：</p>
<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
</code></pre></div></div>

<p>向<code class="language-plaintext highlighter-rouge">core-site.xml</code>添加如下内容：</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>       <span class="nt">&lt;value&gt;</span>hdfs://node2:9000/<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>     <span class="nt">&lt;value&gt;</span>/home/hadoop/hdpdata<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>
<p>在<code class="language-plaintext highlighter-rouge">hdfs-site.xml</code>中加入如下内容：</p>
<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>2<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>file:///home/hadoop/namenode<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>

<p>在<code class="language-plaintext highlighter-rouge">mapred-site.xml</code>中加入如下内容：</p>
<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>

<p>在<code class="language-plaintext highlighter-rouge">yarn-site.xml</code>中加入如下内容：</p>
<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>node2<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.hostname<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>node2<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
    <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
    <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>

<p>在<code class="language-plaintext highlighter-rouge">slaves</code>文件内加入如下内容：</p>
<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>node1
node2
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">slaves</code>内的内容代表<code class="language-plaintext highlighter-rouge">datanode</code>结点。</p>

<p>注意上面的配置在一台结点配置好了之后一定要将它们发送到所有结点，使得所有结点的<code class="language-plaintext highlighter-rouge">hadoop</code>配置相同。</p>

<h5 id="格式化namenode">格式化namenode</h5>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs namenode <span class="nt">-format</span>
</code></pre></div></div>

<h5 id="启动hadoop">启动hadoop</h5>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>start-dfs.sh
start-yarn.sh
</code></pre></div></div>

<p>输入<code class="language-plaintext highlighter-rouge">jps</code>，查看显示结果是否各个组件都成功启动：</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9461 ResourceManager
8999 NameNode
9131 DataNode
9293 SecondaryNameNode
15038 Jps
9582 NodeManager
</code></pre></div></div>
<p>如果某个组件没有成功启动，可以查看<code class="language-plaintext highlighter-rouge">$HADOOP_HOME/logs/</code>下相应的日志文件。</p>

<h5 id="测试hadoop">测试hadoop</h5>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mkdir</span> /input
hdfs dfs <span class="nt">-copyFromLocal</span> /home/hadoop/words.txt /input/
hdfs dfs <span class="nt">-ls</span> /input
hdfs dfs <span class="nt">-cat</span> /input/words.txt
</code></pre></div></div>

<p>好了可以愉快的玩耍了。。。</p>

<h4 id="补充网络知识">补充网络知识：</h4>

<h5 id="服务器公网ip">服务器公网ip</h5>

<p>可以用于域名解析ip，服务器远程登录ip，是最主要的服务器ip地址。</p>

<h5 id="内网ip">内网ip</h5>

<p>不能用于域名解析。</p>

<p>不可以直接用于服务器远程登录，其主要作用是：跟当前帐号下的其他同集群的机器通信。 
　</p>

<p>一些小型企业或者学校，通常都是申请一个固定的IP地址，然后通过IP共享（IP Sharing），使用整个公司或学校的机器都能够访问互联网。而这些企业或学校的机器使用的IP地址就是内网IP，内网IP是在规划IPv4协议时，考虑到IP地址资源可能不足，就专门为内部网设计私有IP地址（或称之为保留地址），一般常用内网IP地址都是这种形式的：10.X.X.X、172.16.X.X-172.31.X.X、192.168.X.X等。需要注意的是，内网的计算机可向Internet上的其他计算机发送连接请求，但Internet上其他的计算机无法向内网的计算机发送连接请求。 
　　</p>

<p>公网IP就是除了保留IP地址以外的IP地址，可以与Internet上的其他计算机随意互相访问。我们通常所说的IP地址，其实就是指的公网 IP。互联网上的每台计算机都有一个独立的IP地址，该IP地址唯一确定互联网上的一台计算机。这里的IP地址就是指的公网IP地址。</p>

<p>其实，互联网上的计算机是通过“公网IP＋内网IP”来唯一确定的，就像很多大楼都是201房间一样，房间号可能一样，但是大楼肯定是唯一的。公网IP地址和内网IP地址也是同样，不同企业或学校的机器可能有相同的内网IP地址，但是他们的公网IP地址肯定不同。那么这些企业或学校的计算机是怎样IP地址共享的呢？这就需要使用NAT（Network Address Translation,网络地址转换）功能。当内部计算机要连接互联网时，首先需要通过NAT技术，将内部计算机数据包中有关IP地址的设置都设成NAT主机的公共IP地址，然后再传送到Internet，虽然内部计算机使用的是私有IP地址，但在连接Internet时，就可以通过NAT主机的NAT技术，将内网我IP地址修改为公网IP地址，如此一来，内网计算机就可以向Internet请求数据了。&lt;/br&gt;
                            ——百度百科</p>
